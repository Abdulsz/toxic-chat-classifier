{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvXg3Qf4pc9P"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "import random\n",
        "from spacy.training.example import Example\n",
        "from spacy.util import minibatch, compounding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Jigsaw_toxic_comment_classification.csv')"
      ],
      "metadata": {
        "id": "UzG-wDNTppEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converting to binary\n",
        "df = df.dropna(subset=['comment_text'])\n",
        "df['is_toxic'] = df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1) > 0\n"
      ],
      "metadata": {
        "id": "OtA_RrELpwg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into training and validation with sklearn\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    df[\"comment_text\"], df[\"is_toxic\"], test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "ZbEidIpuoQWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Standardized format\n",
        "train_data = [\n",
        "    (text, {\"cats\": {\"TOXIC\": label, \"NOT_TOXIC\": not label}})\n",
        "    for text, label in zip(train_texts, train_labels)\n",
        "]\n",
        "len(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sZkkb9plomeV",
        "outputId": "167c37f8-398c-4f99-96a2-afd1a207a30c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "127656"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_data = list(zip(val_texts.tolist(), val_labels.tolist())) #validation data"
      ],
      "metadata": {
        "id": "-EuRrFBfpbOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define eval function\n",
        "def evaluate_model(nlp, val_data):\n",
        "    preds = []\n",
        "    truths = []\n",
        "    for text, true_label in val_data:\n",
        "        doc = nlp(text)\n",
        "        score = doc.cats[\"TOXIC\"]\n",
        "        pred_label = score >= 0.5\n",
        "        preds.append(pred_label)\n",
        "        truths.append(true_label)\n",
        "    acc = accuracy_score(truths, preds)\n",
        "    prec = precision_score(truths, preds)\n",
        "    rec = recall_score(truths, preds)\n",
        "    f1 = f1_score(truths, preds)\n",
        "    return acc, prec, rec, f1"
      ],
      "metadata": {
        "id": "_Iwbg0vyqLyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I4kBxw8vsON7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create and configure SpaCy pipeline\n",
        "nlp = spacy.blank(\"en\")\n",
        "textcat = nlp.add_pipe(\"textcat\", last = True)\n",
        "textcat.add_label(\"TOXIC\")\n",
        "textcat.add_label(\"NOT_TOXIC\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAlYsnFxqvt5",
        "outputId": "ed8dbe2d-4413-4ffd-b7cf-1795c42ed5f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin training\n",
        "optimizer = nlp.begin_training()"
      ],
      "metadata": {
        "id": "Qh0Z85PBse5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5):\n",
        "    random.shuffle(train_data)\n",
        "    losses = {}\n",
        "    batches = minibatch(train_data, size=compounding(4.0, 32.0, 1.001))\n",
        "    for batch in batches:\n",
        "        examples = []\n",
        "        for text, annotations in batch:\n",
        "            doc = nlp.make_doc(text)\n",
        "            example = Example.from_dict(doc, annotations)\n",
        "            examples.append(example)\n",
        "        nlp.update(examples, losses=losses, drop=0.2, sgd=optimizer)\n",
        "    print(f\"Epoch {epoch} Losses: {losses}\")\n",
        "\n",
        "    # Evaluate\n",
        "    acc, prec, rec, f1 = evaluate_model(nlp, val_data)\n",
        "    print(f\"Epoch {epoch} Validation → Acc: {acc:.4f} | Precision: {prec:.4f} | Recall: {rec:.4f} | F1: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZPivMvutDkt",
        "outputId": "8c995e0e-69af-4eda-d03f-dac733e56a9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Losses: {'textcat': 240.44998453153778}\n",
            "Epoch 0 Validation → Acc: 0.9578 | Precision: 0.9267 | Recall: 0.6353 | F1: 0.7538\n",
            "Epoch 1 Losses: {'textcat': 170.581704998401}\n",
            "Epoch 1 Validation → Acc: 0.9620 | Precision: 0.8776 | Recall: 0.7275 | F1: 0.7956\n",
            "Epoch 2 Losses: {'textcat': 152.66268593579485}\n",
            "Epoch 2 Validation → Acc: 0.9621 | Precision: 0.8241 | Recall: 0.7975 | F1: 0.8106\n",
            "Epoch 3 Losses: {'textcat': 143.6819344264939}\n",
            "Epoch 3 Validation → Acc: 0.9625 | Precision: 0.8360 | Recall: 0.7855 | F1: 0.8099\n",
            "Epoch 4 Losses: {'textcat': 137.14343163725422}\n",
            "Epoch 4 Validation → Acc: 0.9635 | Precision: 0.8491 | Recall: 0.7790 | F1: 0.8125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.to_disk(\"toxic_chat_model_full\")"
      ],
      "metadata": {
        "id": "dCGTPlVNuIp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Code for extracting data from reddit. NOT USED ANYMORE\n",
        "'''\n",
        "!pip install praw\n",
        "\n",
        "# Authenticate\n",
        "reddit = praw.Reddit(\n",
        "    client_id=\"PBqbtbQCnmAY7Y5z1XURiQ\",\n",
        "    client_secret=\"ICVvf_VaNxirOVhJIapz4o-0rgSf0w\",\n",
        "    username=\"abdstz\",\n",
        "    password=\"Timalma1\",\n",
        "    user_agent=\"toxic-chat-scraper\"\n",
        ")\n",
        "subreddit = reddit.subreddit('VALORANT')\n",
        "'''"
      ],
      "metadata": {
        "id": "sgRfFNbcDb8h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}